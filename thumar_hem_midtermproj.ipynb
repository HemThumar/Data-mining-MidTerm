{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd86b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to the Data Transaction Analysis Tool!\n",
      "Please select a dataset to analyze or exit the program:\n",
      "1. AMAZON\n",
      "2. COSTCO\n",
      "3. DMART\n",
      "4. WALMART\n",
      "5. KMART\n",
      "0. Exit\n",
      "Enter the dataset number for analyzing (0 to exit): 1\n",
      "Successfully loaded 20 transactions from AMAZON.\n",
      "Please enter the minimum support threshold (Example: 10 for 10%): 20\n",
      "Please enter the minimum confidence threshold (Example: 10 for 10%): 20\n",
      "\n",
      "Analyzing dataset: AMAZON with support threshold: 20.00% and confidence threshold: 20.00%...\n",
      "\n",
      "Brute Force Frequent Itemsets:\n",
      "{1: {'Cereal': 11, 'Detergent': 11, 'Shampoo': 10, 'Coffee': 10, 'Bread': 6, 'Milk': 8, 'Soap': 7, 'Toothpaste': 4, 'Diapers': 6}, 2: {('Cereal', 'Detergent'): 5, ('Cereal', 'Shampoo'): 6, ('Detergent', 'Shampoo'): 7, ('Cereal', 'Coffee'): 4, ('Cereal', 'Bread'): 4, ('Cereal', 'Soap'): 5, ('Shampoo', 'Soap'): 4, ('Shampoo', 'Coffee'): 4, ('Detergent', 'Coffee'): 6, ('Detergent', 'Milk'): 5, ('Coffee', 'Milk'): 6}}\n",
      "Execution Time (Brute Force): 0.0050 seconds\n",
      "\n",
      "Frequent Itemsets (Apriori):\n",
      "(    support                   itemsets\n",
      "0      0.30                    (Bread)\n",
      "1      0.55                   (Cereal)\n",
      "2      0.50                   (Coffee)\n",
      "3      0.55                (Detergent)\n",
      "4      0.30                  (Diapers)\n",
      "5      0.40                     (Milk)\n",
      "6      0.50                  (Shampoo)\n",
      "7      0.35                     (Soap)\n",
      "8      0.20               (Toothpaste)\n",
      "9      0.20            (Cereal, Bread)\n",
      "10     0.20           (Coffee, Cereal)\n",
      "11     0.25        (Detergent, Cereal)\n",
      "12     0.30          (Shampoo, Cereal)\n",
      "13     0.25             (Cereal, Soap)\n",
      "14     0.30        (Coffee, Detergent)\n",
      "15     0.30             (Coffee, Milk)\n",
      "16     0.20          (Coffee, Shampoo)\n",
      "17     0.25          (Detergent, Milk)\n",
      "18     0.35       (Shampoo, Detergent)\n",
      "19     0.20            (Shampoo, Soap)\n",
      "20     0.25  (Coffee, Detergent, Milk),             antecedents          consequents  antecedent support  \\\n",
      "0              (Cereal)              (Bread)                0.55   \n",
      "1               (Bread)             (Cereal)                0.30   \n",
      "2              (Coffee)             (Cereal)                0.50   \n",
      "3              (Cereal)             (Coffee)                0.55   \n",
      "4           (Detergent)             (Cereal)                0.55   \n",
      "5              (Cereal)          (Detergent)                0.55   \n",
      "6             (Shampoo)             (Cereal)                0.50   \n",
      "7              (Cereal)            (Shampoo)                0.55   \n",
      "8              (Cereal)               (Soap)                0.55   \n",
      "9                (Soap)             (Cereal)                0.35   \n",
      "10             (Coffee)          (Detergent)                0.50   \n",
      "11          (Detergent)             (Coffee)                0.55   \n",
      "12             (Coffee)               (Milk)                0.50   \n",
      "13               (Milk)             (Coffee)                0.40   \n",
      "14             (Coffee)            (Shampoo)                0.50   \n",
      "15            (Shampoo)             (Coffee)                0.50   \n",
      "16          (Detergent)               (Milk)                0.55   \n",
      "17               (Milk)          (Detergent)                0.40   \n",
      "18            (Shampoo)          (Detergent)                0.50   \n",
      "19          (Detergent)            (Shampoo)                0.55   \n",
      "20            (Shampoo)               (Soap)                0.50   \n",
      "21               (Soap)            (Shampoo)                0.35   \n",
      "22  (Coffee, Detergent)               (Milk)                0.30   \n",
      "23       (Coffee, Milk)          (Detergent)                0.30   \n",
      "24    (Detergent, Milk)             (Coffee)                0.25   \n",
      "25             (Coffee)    (Detergent, Milk)                0.50   \n",
      "26          (Detergent)       (Coffee, Milk)                0.55   \n",
      "27               (Milk)  (Coffee, Detergent)                0.40   \n",
      "\n",
      "    consequent support  support  confidence      lift  leverage  conviction  \\\n",
      "0                 0.30     0.20    0.363636  1.212121    0.0350    1.100000   \n",
      "1                 0.55     0.20    0.666667  1.212121    0.0350    1.350000   \n",
      "2                 0.55     0.20    0.400000  0.727273   -0.0750    0.750000   \n",
      "3                 0.50     0.20    0.363636  0.727273   -0.0750    0.785714   \n",
      "4                 0.55     0.25    0.454545  0.826446   -0.0525    0.825000   \n",
      "5                 0.55     0.25    0.454545  0.826446   -0.0525    0.825000   \n",
      "6                 0.55     0.30    0.600000  1.090909    0.0250    1.125000   \n",
      "7                 0.50     0.30    0.545455  1.090909    0.0250    1.100000   \n",
      "8                 0.35     0.25    0.454545  1.298701    0.0575    1.191667   \n",
      "9                 0.55     0.25    0.714286  1.298701    0.0575    1.575000   \n",
      "10                0.55     0.30    0.600000  1.090909    0.0250    1.125000   \n",
      "11                0.50     0.30    0.545455  1.090909    0.0250    1.100000   \n",
      "12                0.40     0.30    0.600000  1.500000    0.1000    1.500000   \n",
      "13                0.50     0.30    0.750000  1.500000    0.1000    2.000000   \n",
      "14                0.50     0.20    0.400000  0.800000   -0.0500    0.833333   \n",
      "15                0.50     0.20    0.400000  0.800000   -0.0500    0.833333   \n",
      "16                0.40     0.25    0.454545  1.136364    0.0300    1.100000   \n",
      "17                0.55     0.25    0.625000  1.136364    0.0300    1.200000   \n",
      "18                0.55     0.35    0.700000  1.272727    0.0750    1.500000   \n",
      "19                0.50     0.35    0.636364  1.272727    0.0750    1.375000   \n",
      "20                0.35     0.20    0.400000  1.142857    0.0250    1.083333   \n",
      "21                0.50     0.20    0.571429  1.142857    0.0250    1.166667   \n",
      "22                0.40     0.25    0.833333  2.083333    0.1300    3.600000   \n",
      "23                0.55     0.25    0.833333  1.515152    0.0850    2.700000   \n",
      "24                0.50     0.25    1.000000  2.000000    0.1250         inf   \n",
      "25                0.25     0.25    0.500000  2.000000    0.1250    1.500000   \n",
      "26                0.30     0.25    0.454545  1.515152    0.0850    1.283333   \n",
      "27                0.30     0.25    0.625000  2.083333    0.1300    1.866667   \n",
      "\n",
      "    zhangs_metric  \n",
      "0        0.388889  \n",
      "1        0.250000  \n",
      "2       -0.428571  \n",
      "3       -0.454545  \n",
      "4       -0.318182  \n",
      "5       -0.318182  \n",
      "6        0.166667  \n",
      "7        0.185185  \n",
      "8        0.511111  \n",
      "9        0.353846  \n",
      "10       0.166667  \n",
      "11       0.185185  \n",
      "12       0.666667  \n",
      "13       0.555556  \n",
      "14      -0.333333  \n",
      "15      -0.333333  \n",
      "16       0.266667  \n",
      "17       0.200000  \n",
      "18       0.428571  \n",
      "19       0.476190  \n",
      "20       0.250000  \n",
      "21       0.192308  \n",
      "22       0.742857  \n",
      "23       0.485714  \n",
      "24       0.666667  \n",
      "25       1.000000  \n",
      "26       0.755556  \n",
      "27       0.866667  )\n",
      "Execution Time (Apriori): 0.0380 seconds\n",
      "\n",
      "Frequent Itemsets (FP-Growth):\n",
      "(    support                   itemsets\n",
      "0      0.55                (Detergent)\n",
      "1      0.55                   (Cereal)\n",
      "2      0.50                  (Shampoo)\n",
      "3      0.50                   (Coffee)\n",
      "4      0.30                    (Bread)\n",
      "5      0.40                     (Milk)\n",
      "6      0.35                     (Soap)\n",
      "7      0.30                  (Diapers)\n",
      "8      0.20               (Toothpaste)\n",
      "9      0.25        (Detergent, Cereal)\n",
      "10     0.35       (Shampoo, Detergent)\n",
      "11     0.30          (Shampoo, Cereal)\n",
      "12     0.20           (Coffee, Cereal)\n",
      "13     0.20          (Coffee, Shampoo)\n",
      "14     0.30        (Coffee, Detergent)\n",
      "15     0.20            (Cereal, Bread)\n",
      "16     0.30             (Coffee, Milk)\n",
      "17     0.25          (Detergent, Milk)\n",
      "18     0.25  (Coffee, Detergent, Milk)\n",
      "19     0.25             (Cereal, Soap)\n",
      "20     0.20            (Shampoo, Soap),             antecedents          consequents  antecedent support  \\\n",
      "0           (Detergent)             (Cereal)                0.55   \n",
      "1              (Cereal)          (Detergent)                0.55   \n",
      "2             (Shampoo)          (Detergent)                0.50   \n",
      "3           (Detergent)            (Shampoo)                0.55   \n",
      "4             (Shampoo)             (Cereal)                0.50   \n",
      "5              (Cereal)            (Shampoo)                0.55   \n",
      "6              (Coffee)             (Cereal)                0.50   \n",
      "7              (Cereal)             (Coffee)                0.55   \n",
      "8              (Coffee)            (Shampoo)                0.50   \n",
      "9             (Shampoo)             (Coffee)                0.50   \n",
      "10             (Coffee)          (Detergent)                0.50   \n",
      "11          (Detergent)             (Coffee)                0.55   \n",
      "12             (Cereal)              (Bread)                0.55   \n",
      "13              (Bread)             (Cereal)                0.30   \n",
      "14             (Coffee)               (Milk)                0.50   \n",
      "15               (Milk)             (Coffee)                0.40   \n",
      "16          (Detergent)               (Milk)                0.55   \n",
      "17               (Milk)          (Detergent)                0.40   \n",
      "18  (Coffee, Detergent)               (Milk)                0.30   \n",
      "19       (Coffee, Milk)          (Detergent)                0.30   \n",
      "20    (Detergent, Milk)             (Coffee)                0.25   \n",
      "21             (Coffee)    (Detergent, Milk)                0.50   \n",
      "22          (Detergent)       (Coffee, Milk)                0.55   \n",
      "23               (Milk)  (Coffee, Detergent)                0.40   \n",
      "24             (Cereal)               (Soap)                0.55   \n",
      "25               (Soap)             (Cereal)                0.35   \n",
      "26            (Shampoo)               (Soap)                0.50   \n",
      "27               (Soap)            (Shampoo)                0.35   \n",
      "\n",
      "    consequent support  support  confidence      lift  leverage  conviction  \\\n",
      "0                 0.55     0.25    0.454545  0.826446   -0.0525    0.825000   \n",
      "1                 0.55     0.25    0.454545  0.826446   -0.0525    0.825000   \n",
      "2                 0.55     0.35    0.700000  1.272727    0.0750    1.500000   \n",
      "3                 0.50     0.35    0.636364  1.272727    0.0750    1.375000   \n",
      "4                 0.55     0.30    0.600000  1.090909    0.0250    1.125000   \n",
      "5                 0.50     0.30    0.545455  1.090909    0.0250    1.100000   \n",
      "6                 0.55     0.20    0.400000  0.727273   -0.0750    0.750000   \n",
      "7                 0.50     0.20    0.363636  0.727273   -0.0750    0.785714   \n",
      "8                 0.50     0.20    0.400000  0.800000   -0.0500    0.833333   \n",
      "9                 0.50     0.20    0.400000  0.800000   -0.0500    0.833333   \n",
      "10                0.55     0.30    0.600000  1.090909    0.0250    1.125000   \n",
      "11                0.50     0.30    0.545455  1.090909    0.0250    1.100000   \n",
      "12                0.30     0.20    0.363636  1.212121    0.0350    1.100000   \n",
      "13                0.55     0.20    0.666667  1.212121    0.0350    1.350000   \n",
      "14                0.40     0.30    0.600000  1.500000    0.1000    1.500000   \n",
      "15                0.50     0.30    0.750000  1.500000    0.1000    2.000000   \n",
      "16                0.40     0.25    0.454545  1.136364    0.0300    1.100000   \n",
      "17                0.55     0.25    0.625000  1.136364    0.0300    1.200000   \n",
      "18                0.40     0.25    0.833333  2.083333    0.1300    3.600000   \n",
      "19                0.55     0.25    0.833333  1.515152    0.0850    2.700000   \n",
      "20                0.50     0.25    1.000000  2.000000    0.1250         inf   \n",
      "21                0.25     0.25    0.500000  2.000000    0.1250    1.500000   \n",
      "22                0.30     0.25    0.454545  1.515152    0.0850    1.283333   \n",
      "23                0.30     0.25    0.625000  2.083333    0.1300    1.866667   \n",
      "24                0.35     0.25    0.454545  1.298701    0.0575    1.191667   \n",
      "25                0.55     0.25    0.714286  1.298701    0.0575    1.575000   \n",
      "26                0.35     0.20    0.400000  1.142857    0.0250    1.083333   \n",
      "27                0.50     0.20    0.571429  1.142857    0.0250    1.166667   \n",
      "\n",
      "    zhangs_metric  \n",
      "0       -0.318182  \n",
      "1       -0.318182  \n",
      "2        0.428571  \n",
      "3        0.476190  \n",
      "4        0.166667  \n",
      "5        0.185185  \n",
      "6       -0.428571  \n",
      "7       -0.454545  \n",
      "8       -0.333333  \n",
      "9       -0.333333  \n",
      "10       0.166667  \n",
      "11       0.185185  \n",
      "12       0.388889  \n",
      "13       0.250000  \n",
      "14       0.666667  \n",
      "15       0.555556  \n",
      "16       0.266667  \n",
      "17       0.200000  \n",
      "18       0.742857  \n",
      "19       0.485714  \n",
      "20       0.666667  \n",
      "21       1.000000  \n",
      "22       0.755556  \n",
      "23       0.866667  \n",
      "24       0.511111  \n",
      "25       0.353846  \n",
      "26       0.250000  \n",
      "27       0.192308  )\n",
      "Execution Time (FP-Growth): 0.0240 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "from itertools import combinations\n",
    "from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Paths to dataset files\n",
    "dataset_files = {\n",
    "    \"AMAZON\": r\"AMAZON.csv\",\n",
    "    \"COSTCO\": r\"COSTCO.csv\",\n",
    "    \"DMART\": r\"DMART.csv\",\n",
    "    \"WALMART\": r\"WALMART.csv\",\n",
    "    \"KMART\": r\"KMART.csv\"\n",
    "}\n",
    "\n",
    "class TransactionAnalyzer:\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.transactions = self.extract_transactions()\n",
    "    \n",
    "    def extract_transactions(self):\n",
    "        \"\"\"Load transaction data from CSV.\"\"\"\n",
    "        with open(self.filepath, newline='') as file:\n",
    "            reader = csv.reader(file)\n",
    "            return [list(filter(None, row)) for row in reader]\n",
    "\n",
    "    def compute_frequent_itemsets(self, support_min):\n",
    "        \"\"\"Brute force method for generating frequent itemsets.\"\"\"\n",
    "        item_frequency = {}\n",
    "        for transaction in self.transactions:\n",
    "            for item in transaction:\n",
    "                item_frequency[item] = item_frequency.get(item, 0) + 1\n",
    "\n",
    "        frequent_sets = {1: {item: count for item, count in item_frequency.items() if count / len(self.transactions) >= support_min}}\n",
    "\n",
    "        k = 2\n",
    "        while True:\n",
    "            prev_itemset = list(frequent_sets[k - 1].keys())\n",
    "            new_item_combinations = list(combinations(prev_itemset, k))\n",
    "            current_count = {}\n",
    "\n",
    "            for transaction in self.transactions:\n",
    "                transaction_set = set(transaction)\n",
    "                for combination in new_item_combinations:\n",
    "                    if set(combination).issubset(transaction_set):\n",
    "                        current_count[combination] = current_count.get(combination, 0) + 1\n",
    "\n",
    "            frequent_sets[k] = {combo: count for combo, count in current_count.items() if count / len(self.transactions) >= support_min}\n",
    "            if not frequent_sets[k]:\n",
    "                del frequent_sets[k]\n",
    "                break\n",
    "            k += 1\n",
    "\n",
    "        return frequent_sets\n",
    "\n",
    "    def run_apriori(self, support_min, confidence_min):\n",
    "        \"\"\"Run the Apriori algorithm.\"\"\"\n",
    "        encoder = TransactionEncoder()\n",
    "        transformed_data = encoder.fit(self.transactions).transform(self.transactions)\n",
    "        df_transactions = pd.DataFrame(transformed_data, columns=encoder.columns_)\n",
    "\n",
    "        frequent_itemsets = apriori(df_transactions, min_support=support_min, use_colnames=True)\n",
    "        rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=confidence_min)\n",
    "\n",
    "        return frequent_itemsets, rules\n",
    "\n",
    "    def run_fpgrowth(self, support_min, confidence_min):\n",
    "        \"\"\"Run the FP-Growth algorithm.\"\"\"\n",
    "        encoder = TransactionEncoder()\n",
    "        transformed_data = encoder.fit(self.transactions).transform(self.transactions)\n",
    "        df_transactions = pd.DataFrame(transformed_data, columns=encoder.columns_)\n",
    "\n",
    "        frequent_itemsets = fpgrowth(df_transactions, min_support=support_min, use_colnames=True)\n",
    "        rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=confidence_min)\n",
    "\n",
    "        return frequent_itemsets, rules\n",
    "\n",
    "def time_algorithm_execution(algorithm_func, *params):\n",
    "    \"\"\"Measure execution time of an algorithm.\"\"\"\n",
    "    start_time = time.time()\n",
    "    output = algorithm_func(*params)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    return output, elapsed_time\n",
    "\n",
    "def main_menu():\n",
    "    \"\"\"User interaction interface.\"\"\"\n",
    "    while True:\n",
    "        print(\"\\nWelcome to the Data Transaction Analysis Tool!\")\n",
    "        print(\"Please select a dataset to analyze or exit the program:\")\n",
    "        \n",
    "        # List available datasets\n",
    "        for index, name in enumerate(dataset_files.keys(), start=1):\n",
    "            print(f\"{index}. {name}\")\n",
    "        print(\"0. Exit\")\n",
    "\n",
    "        try:\n",
    "            user_input = int(input(\"Enter the dataset number for analyzing (0 to exit): \"))\n",
    "            if user_input < 0 or user_input > len(dataset_files):\n",
    "                raise ValueError(\"Invalid choice. Please select a valid option.\")\n",
    "\n",
    "            if user_input == 0:\n",
    "                print(\"Thank you for using the program! Goodbye!\")\n",
    "                break\n",
    "\n",
    "            selected_dataset = list(dataset_files.keys())[user_input - 1]\n",
    "            analyzer = TransactionAnalyzer(dataset_files[selected_dataset])\n",
    "            print(f\"Successfully loaded {len(analyzer.transactions)} transactions from {selected_dataset}.\")\n",
    "\n",
    "            # Get user-defined thresholds\n",
    "            support_input = float(input(\"Please enter the minimum support threshold (Example: 10 for 10%): \")) / 100\n",
    "            confidence_input = float(input(\"Please enter the minimum confidence threshold (Example: 10 for 10%): \")) / 100\n",
    "\n",
    "            print(f\"\\nAnalyzing dataset: {selected_dataset} with support threshold: {support_input * 100:.2f}% and confidence threshold: {confidence_input * 100:.2f}%...\")\n",
    "\n",
    "            # Brute Force Frequent Itemsets\n",
    "            brute_force_result, bf_execution_time = time_algorithm_execution(analyzer.compute_frequent_itemsets, support_input)\n",
    "            print(f\"\\nBrute Force Frequent Itemsets:\\n{brute_force_result}\")\n",
    "            print(f\"Execution Time (Brute Force): {bf_execution_time:.4f} seconds\")\n",
    "\n",
    "            # Apriori Algorithm\n",
    "            apriori_result, apriori_time = time_algorithm_execution(analyzer.run_apriori, support_input, confidence_input)\n",
    "            print(f\"\\nFrequent Itemsets (Apriori):\\n{apriori_result}\")\n",
    "            print(f\"Execution Time (Apriori): {apriori_time:.4f} seconds\")\n",
    "\n",
    "            # FP-Growth Algorithm\n",
    "            fpgrowth_result, fp_execution_time = time_algorithm_execution(analyzer.run_fpgrowth, support_input, confidence_input)\n",
    "            print(f\"\\nFrequent Itemsets (FP-Growth):\\n{fpgrowth_result}\")\n",
    "            print(f\"Execution Time (FP-Growth): {fp_execution_time:.4f} seconds\")\n",
    "\n",
    "            # Ask user if they want to analyze another dataset\n",
    "            retry = input(\"\\nWould you like to analyze a different dataset? (yes/no): \").strip().lower()\n",
    "            if retry != 'yes':\n",
    "                print(\"Thank you for using the program! Goodbye!\")\n",
    "                break\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Error: {e}. Please try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_menu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980e2283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
